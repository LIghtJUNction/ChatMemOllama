# ChatMemOllama

一个个人微信公众号聊天机器人，使用本地 ai 模型（ollma 提供），以及 mem0 管理记忆(测试)

## 注意 目前正在测试中

请使用 old_version 以获得更好的聊天体验

新版正在开发测试

# issue

仓库里的测试版 多人聊天逻辑问题

已经测试实现的功能:
使用 tool calling 实现大模型执行联网查询功能(正在测试)

使用 mem0 添加 提取记忆(速度慢,已经发布，仅供代码参考测试)

# 正在开发:

融合第一版和第二版
仅在关键处调用 mem0 保存和加载记忆("运用 tool_call : function 让模型自主决策是否需要加载之前的记忆")
处理微信 5 秒回复时间限制，如果遇到需要超过 5 秒时间回答用户的情况先返回提示，让用户等待（关键词：继续）
尽量快的回答用户

# 建议

自己部署作为个人 ai 助理时，系统提示词写在 modelfile 里更好，详细方法请见 ollama 文档
