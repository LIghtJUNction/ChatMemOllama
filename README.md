# ChatMemOllama

一个个人微信公众号聊天机器人，使用本地ai模型（ollma提供），以及mem0管理记忆(测试)

## 注意 目前正在测试中

请使用old_version 以获得更好的聊天体验


新版正在开发测试

# issue
仓库里的测试版 多人聊天逻辑问题

已经测试实现的功能:
使用tool calling 实现大模型执行联网查询功能(正在测试)

使用mem0添加 提取记忆(速度慢,已经发布，仅供代码参考测试)

# 正在开发:

融合第一版和第二版
仅在关键处调用mem0保存和加载记忆("运用 tool_call : function 让模型自主决策是否需要加载之前的记忆")
处理微信5秒回复时间限制，如果遇到需要超过5秒时间回答用户的情况先返回提示，让用户等待（关键词：继续）
尽量快的回答用户

# 建议
自己部署作为个人ai助理时，系统提示词写在modelfile里更好，详细方法请见ollama文档
