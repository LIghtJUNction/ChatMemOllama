# ChatMemOllama

一个个人微信公众号聊天机器人👀️ ，使用本地 ai 模型（ollma🚀️  提供），以及 mem0 管理记忆(测试)

> 联系我--email: lightjunction.me@gmail.com

## 注意 目前正在测试中

请使用 old_version 以获得更好的聊天体验

新版正在开发测试

## issue

* 仓库里的测试版 多人聊天逻辑问题


* 使用 mem0 添加 提取记忆(速度慢,已经发布，仅供代码参考测试),不应该时刻调用，应该仅作为保存长期记忆使用

## 正在开发

* [ ] 融合第一版和第二版
* [ ] 仅在关键处调用 mem0 保存和加载记忆("运用 tool_call : function 让模型自主决策是否需要加载之前的记忆")
* [ ] 处理微信 5 秒回复时间限制，如果遇到需要超过 5 秒时间回答用户的情况先返回提示，让用户等待（关键词：继续）
* [ ] 尽量快的回答用户
* [ ] 加入联网查询功能
* [ ] 添加对其他微信消息的处理

## 建议

自己部署作为个人 ai 助理时，系统提示词写在 modelfile 里更好，详细方法请见 ollama 文档



## 个人对ai记忆的看法

本质没有记忆，只有上下文

因此让ai拥有记忆最根本的做法就是在模型内部实现一个记忆神经网络层----以参数的形式将记忆内化于模型之中，并且是模块化的加载方式

challenges:

1. 对算力有要求
2. 将记忆以参数方式储存的具体方式
